{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HF_ColBERT' from 'transformers' (/Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# https://huggingface.co/jinaai/jina-colbert-v1-en\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Load model directly\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, HF_ColBERT\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjinaai/jina-colbert-v1-en\u001b[39m\u001b[38;5;124m\"\u001b[39m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m HF_ColBERT\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjinaai/jina-colbert-v1-en\u001b[39m\u001b[38;5;124m\"\u001b[39m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'HF_ColBERT' from 'transformers' (/Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/jinaai/jina-colbert-v1-en\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, HF_ColBERT\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"jinaai/jina-colbert-v1-en\", trust_remote_code=True)\n",
    "model = HF_ColBERT.from_pretrained(\"jinaai/jina-colbert-v1-en\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAAI/bge-reranker-large\n",
    "https://huggingface.co/BAAI/bge-reranker-large?library=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d28cafa38bb74271b6702f599322810f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c441c833a6d469f8ee7b4b84a8461de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e02a40d4e244123b82aa648690b35d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee449ef73b14447c95b38525c1b68eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1fbda2bb2a94c0c8080755498856cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/801 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def49f760995408ba8e615fcee0d56c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "  \n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"BAAI/bge-reranker-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6c7ed145ed417fb1680b9a78c40e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/394 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f8792a60e74bdd8c95a037c4f3353e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84388d602dc647d3939035803e94d379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/439k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07443d6a09464682a6845ce4343127ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d07117bca149f8b89cf325b518c6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c2a3cfb36a4267855b28f0f018c387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.30G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.855  0.8525]\n",
      " [0.874  0.856 ]]\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import FlagModel\n",
    "sentences_1 = [\"样例数据-1\", \"样例数据-2\"]\n",
    "sentences_2 = [\"样例数据-3\", \"样例数据-4\"]\n",
    "model = FlagModel('BAAI/bge-large-zh-v1.5', \n",
    "                  query_instruction_for_retrieval=\"为这个句子生成表示以用于检索相关文章：\",\n",
    "                  use_fp16=True) # Setting use_fp16 to True speeds up computation with a slight performance degradation\n",
    "embeddings_1 = model.encode(sentences_1)\n",
    "embeddings_2 = model.encode(sentences_2)\n",
    "similarity = embeddings_1 @ embeddings_2.T\n",
    "print(similarity)\n",
    "\n",
    "# for s2p(short query to long passage) retrieval task, suggest to use encode_queries() which will automatically add the instruction to each query\n",
    "# corpus in retrieval task can still use encode() or encode_corpus(), since they don't need instruction\n",
    "queries = ['query_1', 'query_2']\n",
    "passages = [\"样例文档-1\", \"样例文档-2\"]\n",
    "q_embeddings = model.encode_queries(queries)\n",
    "p_embeddings = model.encode(passages)\n",
    "scores = q_embeddings @ p_embeddings.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3372, 0.2048],\n",
       "       [0.226 , 0.3848]], dtype=float16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a0b01017a84aa7bcc962ac49423612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5059a1a8f8b44fcb8478cbe78b71bd23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e972fc93be4d17ba62c84690cbcb09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/30.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85db17da94a4ac283720609c4c5ed5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcb989cf7f24708aaaf80a4274fb0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://huggingface.co/BAAI/bge-reranker-large?library=true\n",
    "from sentence_transformers import SentenceTransformer\n",
    "queries = ['query_1', 'query_2']\n",
    "passages = [\"样例文档-1\", \"样例文档-2\"]\n",
    "instruction = \"为这个句子生成表示以用于检索相关文章：\" # Generate a representation of this sentence for use in retrieving relevant articles\n",
    "\n",
    "model = SentenceTransformer('BAAI/bge-large-zh-v1.5')\n",
    "q_embeddings = model.encode([instruction+q for q in queries], normalize_embeddings=True)\n",
    "p_embeddings = model.encode(passages, normalize_embeddings=True)\n",
    "scores = q_embeddings @ p_embeddings.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33725047, 0.20507805],\n",
       "       [0.22591078, 0.38495797]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from colbert.modeling.checkpoint import Checkpoint\n",
    "# from colbert.infra import ColBERTConfig\n",
    "\n",
    "# query = [\"How to use ColBERT for indexing long documents?\"]\n",
    "# documents = [\n",
    "#     \"ColBERT is an efficient and effective passage retrieval model.\",\n",
    "#     \"Jina-ColBERT is a ColBERT-style model but based on JinaBERT so it can support both 8k context length.\",\n",
    "#     \"JinaBERT is a BERT architecture that supports the symmetric bidirectional variant of ALiBi to allow longer sequence length.\",\n",
    "#     \"Jina-ColBERT model is trained on MSMARCO passage ranking dataset, following a very similar training procedure with ColBERTv2.\",\n",
    "# ]\n",
    "\n",
    "# config = ColBERTConfig(query_maxlen=32, doc_maxlen=512)\n",
    "# ckpt = Checkpoint(args.reranker, colbert_config=colbert_config)\n",
    "# Q = ckpt.queryFromText([all_queries[i]])\n",
    "# D = ckpt.docFromText(all_passages, bsize=32)[0]\n",
    "# D_mask = torch.ones(D.shape[:2], dtype=torch.long)\n",
    "# scores = colbert_score(Q, D, D_mask).flatten().cpu().numpy().tolist()\n",
    "# ranking = numpy.argsort(scores)[::-1]\n",
    "# print(ranking)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
