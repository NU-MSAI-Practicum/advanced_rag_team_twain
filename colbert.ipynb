{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HF_ColBERT' from 'transformers' (/Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# https://huggingface.co/jinaai/jina-colbert-v1-en\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Load model directly\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, HF_ColBERT\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjinaai/jina-colbert-v1-en\u001b[39m\u001b[38;5;124m\"\u001b[39m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m HF_ColBERT\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjinaai/jina-colbert-v1-en\u001b[39m\u001b[38;5;124m\"\u001b[39m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'HF_ColBERT' from 'transformers' (/Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/jinaai/jina-colbert-v1-en\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, HF_ColBERT\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"jinaai/jina-colbert-v1-en\", trust_remote_code=True)\n",
    "model = HF_ColBERT.from_pretrained(\"jinaai/jina-colbert-v1-en\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAAI/bge-reranker-large\n",
    "https://huggingface.co/BAAI/bge-reranker-large?library=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d28cafa38bb74271b6702f599322810f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c441c833a6d469f8ee7b4b84a8461de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e02a40d4e244123b82aa648690b35d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee449ef73b14447c95b38525c1b68eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1fbda2bb2a94c0c8080755498856cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/801 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def49f760995408ba8e615fcee0d56c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "  \n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"BAAI/bge-reranker-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6c7ed145ed417fb1680b9a78c40e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/394 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f8792a60e74bdd8c95a037c4f3353e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84388d602dc647d3939035803e94d379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/439k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07443d6a09464682a6845ce4343127ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d07117bca149f8b89cf325b518c6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c2a3cfb36a4267855b28f0f018c387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.30G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.855  0.8525]\n",
      " [0.874  0.856 ]]\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import FlagModel\n",
    "sentences_1 = [\"样例数据-1\", \"样例数据-2\"]\n",
    "sentences_2 = [\"样例数据-3\", \"样例数据-4\"]\n",
    "model = FlagModel('BAAI/bge-large-zh-v1.5', \n",
    "                  query_instruction_for_retrieval=\"为这个句子生成表示以用于检索相关文章：\",\n",
    "                  use_fp16=True) # Setting use_fp16 to True speeds up computation with a slight performance degradation\n",
    "embeddings_1 = model.encode(sentences_1)\n",
    "embeddings_2 = model.encode(sentences_2)\n",
    "similarity = embeddings_1 @ embeddings_2.T\n",
    "print(similarity)\n",
    "\n",
    "# for s2p(short query to long passage) retrieval task, suggest to use encode_queries() which will automatically add the instruction to each query\n",
    "# corpus in retrieval task can still use encode() or encode_corpus(), since they don't need instruction\n",
    "queries = ['query_1', 'query_2']\n",
    "passages = [\"样例文档-1\", \"样例文档-2\"]\n",
    "q_embeddings = model.encode_queries(queries)\n",
    "p_embeddings = model.encode(passages)\n",
    "scores = q_embeddings @ p_embeddings.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3372, 0.2048],\n",
       "       [0.226 , 0.3848]], dtype=float16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a0b01017a84aa7bcc962ac49423612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5059a1a8f8b44fcb8478cbe78b71bd23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e972fc93be4d17ba62c84690cbcb09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/30.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85db17da94a4ac283720609c4c5ed5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcb989cf7f24708aaaf80a4274fb0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://huggingface.co/BAAI/bge-reranker-large?library=true\n",
    "from sentence_transformers import SentenceTransformer\n",
    "queries = ['query_1', 'query_2']\n",
    "passages = [\"样例文档-1\", \"样例文档-2\"]\n",
    "instruction = \"为这个句子生成表示以用于检索相关文章：\" # Generate a representation of this sentence for use in retrieving relevant articles\n",
    "\n",
    "model = SentenceTransformer('BAAI/bge-large-zh-v1.5')\n",
    "q_embeddings = model.encode([instruction+q for q in queries], normalize_embeddings=True)\n",
    "p_embeddings = model.encode(passages, normalize_embeddings=True)\n",
    "scores = q_embeddings @ p_embeddings.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4d6cee8e694f86adedf974cb252b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6b818ae5504380925e128478818fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c56906fdec497085a361eecb631be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23447170b13643aa9d740c490cdba6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126a4190c23946aaa0a862f5b43b86d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/779 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d101eb2ef540479d4b3ff4013664d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8755 0.8794]\n",
      " [0.8716 0.8677]]\n"
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import FlagModel\n",
    "sentences_1 = [\"Sample data-1\", \"Sample data-2\"]\n",
    "sentences_2 = [\"Sample data-3\", \"Sample data-4\"]\n",
    "model = FlagModel('BAAI/bge-large-en-v1.5', \n",
    "                  query_instruction_for_retrieval=\"Represent this sentence for searching relevant passages: \",\n",
    "                  use_fp16=True) # Setting use_fp16 to True speeds up computation with a slight performance degradation\n",
    "embeddings_1 = model.encode(sentences_1)\n",
    "embeddings_2 = model.encode(sentences_2)\n",
    "similarity = embeddings_1 @ embeddings_2.T\n",
    "print(similarity)\n",
    "\n",
    "# for s2p (short query to long passage) retrieval task, suggest to use encode_queries() which will automatically add the instruction to each query\n",
    "# corpus in retrieval task can still use encode() or encode_corpus(), since they don't need instruction\n",
    "queries = ['query_1', 'query_2']\n",
    "passages = [\"Sample document-1\", \"Sample document-2\"]\n",
    "q_embeddings = model.encode_queries(queries)\n",
    "p_embeddings = model.encode(passages)\n",
    "scores = q_embeddings @ p_embeddings.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-ranking BGE small\n",
    "https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.6085,  5.7623])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-large')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('BAAI/bge-reranker-large')\n",
    "model.eval()\n",
    "\n",
    "pairs = [['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']]\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "    scores = model(**inputs, return_dict=True).logits.view(-1, ).float()\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "here\n"
     ]
    }
   ],
   "source": [
    "# make new db\n",
    "from CreateDocuments import create_chunks\n",
    "import RAG_utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# chunks_file_path = create_chunks(1000, 200, 'rag-dataset-12000/data/train-00000-of-00001-9df3a936e1f63191.parquet')\n",
    "# dataset = 'rag-dataset-12000'\n",
    "\n",
    "collection_name = 'chroma_' + dataset + '_' + str(1000) + '_' + str(200) + '_' + 'all-MiniLM-L6-v2'\n",
    "vs = RAG_utils.create_chroma_db(chunks_file_path, collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(name=chroma_rag-dataset-12000_1000_200_all-MiniLM-L6-v2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'create_chroma_db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# db = RAG_utils.access_chroma_db(collection_name='train_1000_200_all-MiniLM-L6-v2')\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mcreate_chroma_db\u001b[49m \n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_chroma_db' is not defined"
     ]
    }
   ],
   "source": [
    "import RAG_utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# db = RAG_utils.access_chroma_db(collection_name='train_1000_200_all-MiniLM-L6-v2')\n",
    "create_chroma_db "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What in heaven’s name does that mean?',\n",
       " 'Madigan means “small dog” in Irish.']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.db.es import search_data, search_vector\n",
    "index_name = 'rag-dataset-12000-train'\n",
    "k = 2\n",
    "question = 'What does the name Madigan mean in Irish?'\n",
    "contexts = [context['_source']['sentence'] for context in search_data(question, index_name, k)]\n",
    "contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Challenge 10: Write a Story From a Movie You Like Hey, Everybody! Sorry it’s been so long. I’ve been working on this How To Train Your Dragon story a lot. […]\\nChallenge 4: Have two of your book characters from different book worlds meet. Write a short story about it. Writefury’s Characters Gilligan: From my first book: “Odd Team Out”. He […]\\nThought I’d add a little bit of Riley Trivia this time. Madigan means “small dog” in Irish. Magnus means “big” in latin. Chapter 6 Training Shyloh After her […]\\nCHAPTER 4 Not a Slave A few days later, all the Irish had been sold. Riley had been sold to a cranky old lady named Freyda. In Freyda’s house, Riley […]\\nCHAPTER 2 Captured Riley opened her eyes and stared upward. Two seagulls squawked overhead. The ground rocked underneath her. She sat up slowly, her head throbbing. Maddy barked happily, Riley […]'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.db.es import search_data, search_vector\n",
    "index_name = 'rag-dataset-12000-train-vector'\n",
    "k = 5\n",
    "question = 'What does the name Madigan mean in Irish?'\n",
    "contexts = [context['_source']['sentence'] for context in search_vector(question, index_name, k)]\n",
    "contexts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_doc = contexts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What does the name Madigan mean in Irish?\n",
      "The primary identifier of a family is its \"name.\" The patronymic of a family is the \"name\" derived from the father, which generally becomes the surname of any of the family's children.\n",
      "page_content='edit* my ancestors were from Clan Ross\\nFamily lore is that we were MacDonalds in Scotland, but chased out. Many family members moved to York and took the name Sturdy.'\n",
      "========== madigan in context\n",
      "1\n",
      "page_content='Challenge 10: Write a Story From a Movie You Like Hey, Everybody! Sorry it’s been so long. I’ve been working on this How To Train Your Dragon story a lot. […]\\nChallenge 4: Have two of your book characters from different book worlds meet. Write a short story about it. Writefury’s Characters Gilligan: From my first book: “Odd Team Out”. He […]\\nThought I’d add a little bit of Riley Trivia this time. Madigan means “small dog” in Irish. Magnus means “big” in latin. Chapter 6 Training Shyloh After her […]\\nCHAPTER 4 Not a Slave A few days later, all the Irish had been sold. Riley had been sold to a cranky old lady named Freyda. In Freyda’s house, Riley […]\\nCHAPTER 2 Captured Riley opened her eyes and stared upward. Two seagulls squawked overhead. The ground rocked underneath her. She sat up slowly, her head throbbing. Maddy barked happily, Riley […]'\n"
     ]
    }
   ],
   "source": [
    "question = 'What does the name Madigan mean in Irish?'\n",
    "\n",
    "system_message = \"\"\"You are a helpful assistant. Answer the user's question in one sentence based on the provided context. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. Do NOT start your response with \"According to the provided context.\" \"\"\"\n",
    "user_message_template = \"\"\"Context: {context} Question: {question}\"\"\"\n",
    "# db.__query_collection\n",
    "# documents = db.similarity_search(question, k=11)\n",
    "documents = [doc[0] for doc in db.similarity_search_with_score(question, k=11)]\n",
    "documents2 = [doc for doc in db.similarity_search(question, k=11)]\n",
    "\n",
    "assert [doc.page_content for doc in documents] == [doc.page_content for doc in documents2]\n",
    "# documents = db._collection.query(\n",
    "#     query_texts=question,\n",
    "#     n_results=5,\n",
    "#     include=[\"embeddings\", \"documents\", \"metadatas\", \"distances\"],\n",
    "# )\n",
    "context = RAG_utils.format_docs([doc for doc in documents])\n",
    "user_message = user_message_template.format(context=context, question=question)\n",
    "\n",
    "answer = RAG_utils.gen_text_ollama(sys_msg=system_message, user_msg=user_message,options={'seed':0, 'temperature':0.01})\n",
    "print(question)\n",
    "print(answer)\n",
    "print(documents[0])\n",
    "if 'madigan' in context.lower():\n",
    "    print('=' * 10, 'madigan in context')\n",
    "    for i, doc in enumerate(documents):\n",
    "        if 'madigan' in doc.page_content.lower():\n",
    "            print(i)\n",
    "            print(doc)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1].page_content == es_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='edit* my ancestors were from Clan Ross\\nFamily lore is that we were MacDonalds in Scotland, but chased out. Many family members moved to York and took the name Sturdy.'),\n",
       "  0.21601745142327888),\n",
       " (Document(page_content='Looking to the future, a resurgence in the popularity of traditional Scottish forenames in recent years is likely to combat Anglicisation, said Hough.\\n“Far more Gaelic and Celtic-derived personal names are being chosen by parents in Scotland, which can be a way of affirming national identity,” she says. “Gaelic-derived forenames that are in the top 100 names in Scotland at the moment include Aiden, Callum and Finlay. Cameron is originally a clan name, and Lewis, Evan and Isla are all place names.”\\nYou can view a map of Scotland’s most popular surnames at Tartan Footprint.Tagged\\nMy father is a Ross. How can I find out about our ancestors\\nMy father is a Simpson from Frazer clan. How can I find out about our ancestors?\\naccording to my grand mother some of my ancestors moved from Scotland to Finland in the early-mid 1700 but i do not know much else than that. it would be really helpful if someone could lead me to other sites and such where i can find out more of stuff like this.'),\n",
       "  0.12532417692359665),\n",
       " (Document(page_content='In the Northern Isles Halcrow, Drever and Flett survive as the third most common surnames, while Shetland still boasts a diverse mix of Spences, Rendalls and Sinclairs. Carole Hough, professor of onomastics – the study of name origins – at Glasgow University, said the surnames of Orkney and Shetland differ from much of mainland Scotland due to naming traditions.\\n“Shetland and Orkney are unique in that they have a much higher proportion of surnames from local place names, which makes them quite distinctive. Place names tend to cluster around their origin, which is surprising given how mobile people are,” she added\\nThe English derived surname Smith is the most dominant across the whole of Great Britain with a considerable stronghold in the lowlands and east of Scotland. Modern-day immigration shows in areas such a Glasgow’s Pollokshield’s East, with Ahmed, Ali and Singh popular surnames. Jones, Davies and Williams dominate in Wales.'),\n",
       "  0.12185700857769644),\n",
       " (Document(page_content='The primary identifier of a family is its “name.” The patronymic of a family is the “name” derived from the father, which generally becomes the surname of any of the family’s children. When a baby girl is “named” after her mother, she has received a metronymic.\\nNow on to two more words that derive from the English root onym meaning “name.” A homonym describes a word whose “name” sounds like another’s but is different in meaning. For instance, the words “dear” as in “precious” and “deer” as in “a four-legged woodland creature with antlers” are homonyms because their “names” sound the same but they have different meanings. An eponym is an imaginary or real person’s “name” put upon a place. An example of an eponym is Europe, whose “name” came from the mythological bull Europa.\\nNow no longer will the root word onym run around anonymously, having no “name,” since at least you will not be fooled!\\n- anonymous: without a ‘name’\\n- pseudonym: false ‘name’'),\n",
       "  0.1113527495233263),\n",
       " (Document(page_content=\"It seemed like a good idea to note why sendai will appear in various place on this blog to describe our bio-mechanical characters. Names having utterly different meanings to their real world counterparts are common in fiction and I'll note one here from my favorite sci-fi novel series; Frank Herbert's 'Dune':\\nBakka in Dune: In Fremen legend, the weeper who mourns for all mankind.\\nBakka in the real world: Japanese (baka) for idiot or fool.\\nBakka in Kvam municipality, Hordaland, Norway\\nBakka in Aurland municipality, Sogn og Fjordane, Norway\\nBakka in Kvinnherad municipality, Hordaland, Norway\\nBakka-Phoenix, a bookstore in Toronto.\"),\n",
       "  0.08543951835967634),\n",
       " (Document(page_content='Baker the Miller. This good idea soon became Tom/and Bill Miller and second names came into style.\\nThe second name was applied to the whole family and Tom Bakers wife and children were also Bakers. The family name was handed on, and Tom Baker’s son kept the name Baker, even if he became a Vut olvar or a carpenter.\\nIn Ireland and Scotland, the second name was often taken from the father’s first name, O‘Brian means son of Brian and MacDonald means son of Donald. Some families were named for places. The Hills and Wells, the Lakes and Woods originally may have been named for the places where they lived. Some families took their names from inns and taverns. Old inns were often named for animals, famous persons or outstanding objects. The family names Lamb and Lyon, Wolf and Swann, King and Queen may date back to ancestors who named themselves after their favorite inns.'),\n",
       "  0.08063359751767607),\n",
       " (Document(page_content='Map Reveals Scots Modern-Day Surnames\\nA map of Great Britain’s most popular surnames shows the dominance that clan areas still hold in Scotland, while other areas show the effects of modern-day immigration. Created by experts from three English Universities, Uncertainty of Identity uses surnames listed on the electoral roll to find the three most popular names in each electoral ward.\\nMackay and Sutherland are the most popular names in the North Highlands, echoing the ancient territories and stronghold of the clans. Mackenzie, Fraser and Ross are the most popular in the area North of Inverness, while MacLeod and MacDonald dominate the Western Isles – data that directly corresponds with clan territory maps.'),\n",
       "  0.06621979679543544),\n",
       " (Document(page_content='Top Definition\\nAnother name for Charleston, South Carolina.\\nMe and my friends are going to chill down in Chucktown. Laaaaaaate!\\nby Jason B. Cook October 27, 2003\\n4 more definitions\\n2\\nA nickname for the City of Charleston, SOUTH CAROLINA ONLY! There is only ONE Chucktown in the USA!! NOT Charleston,WV!! Don\\'t get it mixed up!\\nI\\'m geechie cuz I\\'m from dat chucktown!\\nby Brian Glover March 26, 2008\\n3\\nChucktown refers to Charleston, South Carolina. Also known as The Chuck, Charlie-o, Chucktezzy, ect. Originally named Charles Town after King Charles, hence \"Chuck\"town. Not the West Virginian city of Charleston. Chucktown was also featured as a question on an episode of discovery channels Cash Cab, just for you West Virginians out there who disagree.\\ndamn i need to leave chucktown.\\n4\\nIt means Charleston, South Carolina the best city in the world\\nAlmost like Atlanta, GA but alot better\\nby Danny White December 27, 2003\\n5\\nA nickname for the city of Charleston, West Virginia.\\nI live in chucktown.'),\n",
       "  0.06402293446365359),\n",
       " (Document(page_content=\"a thicker connection with my son. It's definitely been challenging being away from Anemo and Suzanne for so long, and I was thrilled last night when we finally figured out how to video chat. At least while I'm away (for only one more week), I'm trying to take in all I can about the language and culture here. Keeping with the theme, I learned two Amharic terms at lunch yesterday using the word ደም (dem, blood): ደም መጣጭ (dem meThaCH), which means an oppressive person, like a bloodsucker I suppose; and ደመኛ (demenya), which can mean brave, or, in a different context, vengeful, as when one feels blood coursing through one's veins. While I probably won't remember these two more advanced terms, by metaphorically swinging two bats, I'll always recall the word ደም.\"),\n",
       "  0.04674963865734283)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'madigan' in context.lower():\n",
    "    print('madigan' in context.lower())\n",
    "    print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from colbert.modeling.checkpoint import Checkpoint\n",
    "# from colbert.infra import ColBERTConfig\n",
    "\n",
    "# query = [\"How to use ColBERT for indexing long documents?\"]\n",
    "# documents = [\n",
    "#     \"ColBERT is an efficient and effective passage retrieval model.\",\n",
    "#     \"Jina-ColBERT is a ColBERT-style model but based on JinaBERT so it can support both 8k context length.\",\n",
    "#     \"JinaBERT is a BERT architecture that supports the symmetric bidirectional variant of ALiBi to allow longer sequence length.\",\n",
    "#     \"Jina-ColBERT model is trained on MSMARCO passage ranking dataset, following a very similar training procedure with ColBERTv2.\",\n",
    "# ]\n",
    "\n",
    "# config = ColBERTConfig(query_maxlen=32, doc_maxlen=512)\n",
    "# ckpt = Checkpoint(args.reranker, colbert_config=colbert_config)\n",
    "# Q = ckpt.queryFromText([all_queries[i]])\n",
    "# D = ckpt.docFromText(all_passages, bsize=32)[0]\n",
    "# D_mask = torch.ones(D.shape[:2], dtype=torch.long)\n",
    "# scores = colbert_score(Q, D, D_mask).flatten().cpu().numpy().tolist()\n",
    "# ranking = numpy.argsort(scores)[::-1]\n",
    "# print(ranking)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jina\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b2f03c96234af6961b3d270c65f46a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "artifact.metadata:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f5ade5e030494d828618cfc2e1bbb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75df7bc788f4608a7ed04053510a6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0943b92b6fc64068bcddfcdc78c535a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/405 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06120c77073a432aa9b0671c574a325b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26e8f52396e4b8d8fde7e574dcd24d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eede7e5c4e84c218050ab14ce1ffcf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[May 18, 17:37:24] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error building extension 'segmented_maxsim_cpp': [1/2] c++ -MMD -MF segmented_maxsim.o.d -DTORCH_EXTENSION_NAME=segmented_maxsim_cpp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_clang\\\" -DPYBIND11_STDLIB=\\\"_libcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1002\\\" -isystem /Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include -isystem /Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include/TH -isystem /Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include/THC -isystem /Users/ryankish/miniforge3/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -c '/Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/colbert/modeling/segmented_maxsim.cpp' -o segmented_maxsim.o \n\u001b[31mFAILED: \u001b[0msegmented_maxsim.o \nc++ -MMD -MF segmented_maxsim.o.d -DTORCH_EXTENSION_NAME=segmented_maxsim_cpp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_clang\\\" -DPYBIND11_STDLIB=\\\"_libcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1002\\\" -isystem /Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include -isystem /Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include/TH -isystem /Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include/THC -isystem /Users/ryankish/miniforge3/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -c '/Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/colbert/modeling/segmented_maxsim.cpp' -o segmented_maxsim.o \nclang: error: no such file or directory: '490'\nclang: error: no such file or directory: 'Practicum'\nclang: error: no such file or directory: 'in'\nclang: error: no such file or directory: 'Intelligent'\nclang: error: no such file or directory: 'Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include'\nclang: error: no such file or directory: '490'\nclang: error: no such file or directory: 'Practicum'\nclang: error: no such file or directory: 'in'\nclang: error: no such file or directory: 'Intelligent'\nclang: error: no such file or directory: 'Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include/torch/csrc/api/include'\nclang: error: no such file or directory: '490'\nclang: error: no such file or directory: 'Practicum'\nclang: error: no such file or directory: 'in'\nclang: error: no such file or directory: 'Intelligent'\nclang: error: no such file or directory: 'Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include/TH'\nclang: error: no such file or directory: '490'\nclang: error: no such file or directory: 'Practicum'\nclang: error: no such file or directory: 'in'\nclang: error: no such file or directory: 'Intelligent'\nclang: error: no such file or directory: 'Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include/THC'\nninja: build stopped: subcommand failed.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/utils/cpp_extension.py:2096\u001b[0m, in \u001b[0;36m_run_ninja_build\u001b[0;34m(build_directory, verbose, error_prefix)\u001b[0m\n\u001b[1;32m   2095\u001b[0m     stdout_fileno \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2096\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2097\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2098\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstdout_fileno\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2099\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTDOUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2104\u001b[0m     \u001b[38;5;66;03m# Python 2 and 3 compatible way of getting the error object.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/subprocess.py:528\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 528\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    529\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['ninja', '-v']' returned non-zero exit status 1.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m      8\u001b[0m documents \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColBERT is an efficient and effective passage retrieval model.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJina-ColBERT is a ColBERT-style model but based on JinaBERT so it can support both 8k context length.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJinaBERT is a BERT architecture that supports the symmetric bidirectional variant of ALiBi to allow longer sequence length.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJina-ColBERT model is trained on MSMARCO passage ranking dataset, following a very similar training procedure with ColBERTv2.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m ]\n\u001b[1;32m     15\u001b[0m config \u001b[38;5;241m=\u001b[39m ColBERTConfig(query_maxlen\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, doc_maxlen\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolbert-ir/colbertv2.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolbert_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mColBERTConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexperiments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m Q \u001b[38;5;241m=\u001b[39m ckpt\u001b[38;5;241m.\u001b[39mqueryFromText(query)\n\u001b[1;32m     18\u001b[0m D \u001b[38;5;241m=\u001b[39m ckpt\u001b[38;5;241m.\u001b[39mdocFromText(documents, bsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/colbert/modeling/checkpoint.py:19\u001b[0m, in \u001b[0;36mCheckpoint.__init__\u001b[0;34m(self, name, colbert_config, verbose)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, colbert_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, verbose:\u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolbert_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m=\u001b[39m verbose\n",
      "File \u001b[0;32m~/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/colbert/modeling/colbert.py:24\u001b[0m, in \u001b[0;36mColBERT.__init__\u001b[0;34m(self, name, colbert_config)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(name, colbert_config)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_gpu \u001b[38;5;241m=\u001b[39m colbert_config\u001b[38;5;241m.\u001b[39mtotal_visible_gpus \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 24\u001b[0m \u001b[43mColBERT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_load_torch_extensions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_gpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolbert_config\u001b[38;5;241m.\u001b[39mmask_punctuation:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskiplist \u001b[38;5;241m=\u001b[39m {w: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     28\u001b[0m                      \u001b[38;5;28;01mfor\u001b[39;00m symbol \u001b[38;5;129;01min\u001b[39;00m string\u001b[38;5;241m.\u001b[39mpunctuation\n\u001b[1;32m     29\u001b[0m                      \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m [symbol, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_tokenizer\u001b[38;5;241m.\u001b[39mencode(symbol, add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]]}\n",
      "File \u001b[0;32m~/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/colbert/modeling/colbert.py:39\u001b[0m, in \u001b[0;36mColBERT.try_load_torch_extensions\u001b[0;34m(cls, use_gpu)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     38\u001b[0m print_message(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m segmented_maxsim_cpp \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msegmented_maxsim_cpp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpathlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;18;43m__file__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msegmented_maxsim.cpp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-O3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCOLBERT_LOAD_TORCH_EXTENSION_VERBOSE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFalse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msegmented_maxsim \u001b[38;5;241m=\u001b[39m segmented_maxsim_cpp\u001b[38;5;241m.\u001b[39msegmented_maxsim_cpp\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_extensions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/utils/cpp_extension.py:1306\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(name,\n\u001b[1;32m   1215\u001b[0m          sources: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m   1216\u001b[0m          extra_cflags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1224\u001b[0m          is_standalone\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1225\u001b[0m          keep_intermediates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;124;03m    Load a PyTorch C++ extension just-in-time (JIT).\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;124;03m        ...     verbose=True)\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_jit_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43msources\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_get_build_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_intermediates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_intermediates\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/utils/cpp_extension.py:1710\u001b[0m, in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1706\u001b[0m                 hipified_sources\u001b[38;5;241m.\u001b[39madd(hipify_result[s_abs]\u001b[38;5;241m.\u001b[39mhipified_path \u001b[38;5;28;01mif\u001b[39;00m s_abs \u001b[38;5;129;01min\u001b[39;00m hipify_result \u001b[38;5;28;01melse\u001b[39;00m s_abs)\n\u001b[1;32m   1708\u001b[0m             sources \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(hipified_sources)\n\u001b[0;32m-> 1710\u001b[0m         \u001b[43m_write_ninja_file_and_build_library\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m            \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1716\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1717\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1718\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1719\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1720\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_standalone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1722\u001b[0m     baton\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/utils/cpp_extension.py:1823\u001b[0m, in \u001b[0;36m_write_ninja_file_and_build_library\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_standalone)\u001b[0m\n\u001b[1;32m   1821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m   1822\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuilding extension module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m-> 1823\u001b[0m \u001b[43m_run_ninja_build\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1826\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mError building extension \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/utils/cpp_extension.py:2112\u001b[0m, in \u001b[0;36m_run_ninja_build\u001b[0;34m(build_directory, verbose, error_prefix)\u001b[0m\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(error, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m error\u001b[38;5;241m.\u001b[39moutput:  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   2111\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;241m*\u001b[39mSUBPROCESS_DECODE_ARGS)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m-> 2112\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error building extension 'segmented_maxsim_cpp': [1/2] c++ -MMD -MF segmented_maxsim.o.d -DTORCH_EXTENSION_NAME=segmented_maxsim_cpp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_clang\\\" -DPYBIND11_STDLIB=\\\"_libcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1002\\\" -isystem /Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include -isystem /Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include/TH -isystem /Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include/THC -isystem /Users/ryankish/miniforge3/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -c '/Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/colbert/modeling/segmented_maxsim.cpp' -o segmented_maxsim.o \n\u001b[31mFAILED: \u001b[0msegmented_maxsim.o \nc++ -MMD -MF segmented_maxsim.o.d -DTORCH_EXTENSION_NAME=segmented_maxsim_cpp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_clang\\\" -DPYBIND11_STDLIB=\\\"_libcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1002\\\" -isystem /Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include -isystem /Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include/TH -isystem /Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include/THC -isystem /Users/ryankish/miniforge3/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -c '/Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/colbert/modeling/segmented_maxsim.cpp' -o segmented_maxsim.o \nclang: error: no such file or directory: '490'\nclang: error: no such file or directory: 'Practicum'\nclang: error: no such file or directory: 'in'\nclang: error: no such file or directory: 'Intelligent'\nclang: error: no such file or directory: 'Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include'\nclang: error: no such file or directory: '490'\nclang: error: no such file or directory: 'Practicum'\nclang: error: no such file or directory: 'in'\nclang: error: no such file or directory: 'Intelligent'\nclang: error: no such file or directory: 'Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include/torch/csrc/api/include'\nclang: error: no such file or directory: '490'\nclang: error: no such file or directory: 'Practicum'\nclang: error: no such file or directory: 'in'\nclang: error: no such file or directory: 'Intelligent'\nclang: error: no such file or directory: 'Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include/TH'\nclang: error: no such file or directory: '490'\nclang: error: no such file or directory: 'Practicum'\nclang: error: no such file or directory: 'in'\nclang: error: no such file or directory: 'Intelligent'\nclang: error: no such file or directory: 'Systems/advanced_rag_team_twain/ragenv/lib/python3.9/site-packages/torch/include/THC'\nninja: build stopped: subcommand failed.\n"
     ]
    }
   ],
   "source": [
    "from colbert.modeling.checkpoint import Checkpoint\n",
    "from colbert.infra import ColBERTConfig\n",
    "import torch\n",
    "from colbert.modeling.colbert import colbert_score\n",
    "import numpy as np\n",
    "\n",
    "query = [\"How to use ColBERT for indexing long documents?\"]\n",
    "documents = [\n",
    "    \"ColBERT is an efficient and effective passage retrieval model.\",\n",
    "    \"Jina-ColBERT is a ColBERT-style model but based on JinaBERT so it can support both 8k context length.\",\n",
    "    \"JinaBERT is a BERT architecture that supports the symmetric bidirectional variant of ALiBi to allow longer sequence length.\",\n",
    "    \"Jina-ColBERT model is trained on MSMARCO passage ranking dataset, following a very similar training procedure with ColBERTv2.\",\n",
    "]\n",
    "\n",
    "config = ColBERTConfig(query_maxlen=32, doc_maxlen=512)\n",
    "ckpt = Checkpoint(\"colbert-ir/colbertv2.0\", colbert_config=ColBERTConfig(root=\"experiments\"))\n",
    "Q = ckpt.queryFromText(query)\n",
    "D = ckpt.docFromText(documents, bsize=32)[0]\n",
    "D_mask = torch.ones(D.shape[:2], dtype=torch.long)\n",
    "scores = colbert_score(Q, D, D_mask).flatten().cpu().numpy().tolist()\n",
    "ranking = np.argsort(scores)[::-1]\n",
    "print(ranking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
