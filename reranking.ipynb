{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== 0 ====================\n",
      "edit* my ancestors were from Clan Ross\n",
      "Family lore is that we were MacDonalds in Scotland, but chased out. Many family members moved to York and took the name Sturdy.\n",
      "==================== 1 ====================\n",
      "Challenge 10: Write a Story From a Movie You Like Hey, Everybody! Sorry it’s been so long. I’ve been working on this How To Train Your Dragon story a lot. […]\n",
      "Challenge 4: Have two of your book characters from different book worlds meet. Write a short story about it. Writefury’s Characters Gilligan: From my first book: “Odd Team Out”. He […]\n",
      "Thought I’d add a little bit of Riley Trivia this time. Madigan means “small dog” in Irish. Magnus means “big” in latin. Chapter 6 Training Shyloh After her […]\n",
      "CHAPTER 4 Not a Slave A few days later, all the Irish had been sold. Riley had been sold to a cranky old lady named Freyda. In Freyda’s house, Riley […]\n",
      "CHAPTER 2 Captured Riley opened her eyes and stared upward. Two seagulls squawked overhead. The ground rocked underneath her. She sat up slowly, her head throbbing. Maddy barked happily, Riley […]\n",
      "==================== 2 ====================\n",
      "The History of Ancient Irish Civilization\n",
      "[Pg v]\n",
      "PREFACE..\n",
      "But the book has a further mission. There are many English and\n",
      "many Anglo-Irish people who think, merely from ignorance, that\n",
      "Ireland was a barbarous and half-savage country before the English\n",
      "came among the people and civilised them. This book, so far as it\n",
      "finds its way among the two classes above mentioned, will, I fancy,\n",
      "open their eyes. They will learn from it that the old Irish, so far from\n",
      "being barbarous,\n",
      "[Pg vi]\n",
      "were a bright, intellectual, and cultured people; that they had\n",
      "professions, trades, and industries pervading the whole population,\n",
      "with clearly defined ranks and grades of society, all working under an\n",
      "elaborate system of native laws; and that in the steadying and\n",
      "civilising arts and pursuits of everyday life they were as well\n",
      "advanced, as orderly, and as regular as any other European people\n",
      "of the same period. They will find too that, as regards education,\n",
      "==================== 3 ====================\n",
      "Looking to the future, a resurgence in the popularity of traditional Scottish forenames in recent years is likely to combat Anglicisation, said Hough.\n",
      "“Far more Gaelic and Celtic-derived personal names are being chosen by parents in Scotland, which can be a way of affirming national identity,” she says. “Gaelic-derived forenames that are in the top 100 names in Scotland at the moment include Aiden, Callum and Finlay. Cameron is originally a clan name, and Lewis, Evan and Isla are all place names.”\n",
      "You can view a map of Scotland’s most popular surnames at Tartan Footprint.Tagged\n",
      "My father is a Ross. How can I find out about our ancestors\n",
      "My father is a Simpson from Frazer clan. How can I find out about our ancestors?\n",
      "according to my grand mother some of my ancestors moved from Scotland to Finland in the early-mid 1700 but i do not know much else than that. it would be really helpful if someone could lead me to other sites and such where i can find out more of stuff like this.\n",
      "==================== 4 ====================\n",
      "In the Northern Isles Halcrow, Drever and Flett survive as the third most common surnames, while Shetland still boasts a diverse mix of Spences, Rendalls and Sinclairs. Carole Hough, professor of onomastics – the study of name origins – at Glasgow University, said the surnames of Orkney and Shetland differ from much of mainland Scotland due to naming traditions.\n",
      "“Shetland and Orkney are unique in that they have a much higher proportion of surnames from local place names, which makes them quite distinctive. Place names tend to cluster around their origin, which is surprising given how mobile people are,” she added\n",
      "The English derived surname Smith is the most dominant across the whole of Great Britain with a considerable stronghold in the lowlands and east of Scotland. Modern-day immigration shows in areas such a Glasgow’s Pollokshield’s East, with Ahmed, Ali and Singh popular surnames. Jones, Davies and Williams dominate in Wales.\n",
      "==================== 5 ====================\n",
      "The primary identifier of a family is its “name.” The patronymic of a family is the “name” derived from the father, which generally becomes the surname of any of the family’s children. When a baby girl is “named” after her mother, she has received a metronymic.\n",
      "Now on to two more words that derive from the English root onym meaning “name.” A homonym describes a word whose “name” sounds like another’s but is different in meaning. For instance, the words “dear” as in “precious” and “deer” as in “a four-legged woodland creature with antlers” are homonyms because their “names” sound the same but they have different meanings. An eponym is an imaginary or real person’s “name” put upon a place. An example of an eponym is Europe, whose “name” came from the mythological bull Europa.\n",
      "Now no longer will the root word onym run around anonymously, having no “name,” since at least you will not be fooled!\n",
      "- anonymous: without a ‘name’\n",
      "- pseudonym: false ‘name’\n",
      "==================== 6 ====================\n",
      "It seemed like a good idea to note why sendai will appear in various place on this blog to describe our bio-mechanical characters. Names having utterly different meanings to their real world counterparts are common in fiction and I'll note one here from my favorite sci-fi novel series; Frank Herbert's 'Dune':\n",
      "Bakka in Dune: In Fremen legend, the weeper who mourns for all mankind.\n",
      "Bakka in the real world: Japanese (baka) for idiot or fool.\n",
      "Bakka in Kvam municipality, Hordaland, Norway\n",
      "Bakka in Aurland municipality, Sogn og Fjordane, Norway\n",
      "Bakka in Kvinnherad municipality, Hordaland, Norway\n",
      "Bakka-Phoenix, a bookstore in Toronto.\n",
      "==================== 7 ====================\n",
      "Baker the Miller. This good idea soon became Tom/and Bill Miller and second names came into style.\n",
      "The second name was applied to the whole family and Tom Bakers wife and children were also Bakers. The family name was handed on, and Tom Baker’s son kept the name Baker, even if he became a Vut olvar or a carpenter.\n",
      "In Ireland and Scotland, the second name was often taken from the father’s first name, O‘Brian means son of Brian and MacDonald means son of Donald. Some families were named for places. The Hills and Wells, the Lakes and Woods originally may have been named for the places where they lived. Some families took their names from inns and taverns. Old inns were often named for animals, famous persons or outstanding objects. The family names Lamb and Lyon, Wolf and Swann, King and Queen may date back to ancestors who named themselves after their favorite inns.\n",
      "==================== 8 ====================\n",
      "What’s the Story?\n",
      "You see, life is just one long story made up of lots of little stories\n",
      "The use of the English language by Irish people is an amazing thing! It took me a long time to work out the meanings of some of the phrases and sayings when I first came here in 1994.\n",
      "In the early days, people would greet me by asking “what’s the craic (crack)?” and I would respond by looking at them as if they had two heads. I then wanted to know exactly what this “craic” was, so I asked “what’s the craic?” and people would reply “Jaysus, the craic’s ninety!”\n",
      "But in Dublin, it’s a little different. I had to learn a whole new phrase when I moved from the west…. “What’s the story?” it just means “how’s things?” but from a yogic angle, it means so much more.\n",
      "You see, life is just one long story made up of lots of little stories. And everyday we all have our own little stories going on. It’s all “head stuff”. We constantly get caught up in tangled webs of different fables and tales.\n",
      "==================== 9 ====================\n",
      "Map Reveals Scots Modern-Day Surnames\n",
      "A map of Great Britain’s most popular surnames shows the dominance that clan areas still hold in Scotland, while other areas show the effects of modern-day immigration. Created by experts from three English Universities, Uncertainty of Identity uses surnames listed on the electoral roll to find the three most popular names in each electoral ward.\n",
      "Mackay and Sutherland are the most popular names in the North Highlands, echoing the ancient territories and stronghold of the clans. Mackenzie, Fraser and Ross are the most popular in the area North of Inverness, while MacLeod and MacDonald dominate the Western Isles – data that directly corresponds with clan territory maps.\n",
      "==================== 10 ====================\n",
      "Top Definition\n",
      "Another name for Charleston, South Carolina.\n",
      "Me and my friends are going to chill down in Chucktown. Laaaaaaate!\n",
      "by Jason B. Cook October 27, 2003\n",
      "4 more definitions\n",
      "2\n",
      "A nickname for the City of Charleston, SOUTH CAROLINA ONLY! There is only ONE Chucktown in the USA!! NOT Charleston,WV!! Don't get it mixed up!\n",
      "I'm geechie cuz I'm from dat chucktown!\n",
      "by Brian Glover March 26, 2008\n",
      "3\n",
      "Chucktown refers to Charleston, South Carolina. Also known as The Chuck, Charlie-o, Chucktezzy, ect. Originally named Charles Town after King Charles, hence \"Chuck\"town. Not the West Virginian city of Charleston. Chucktown was also featured as a question on an episode of discovery channels Cash Cab, just for you West Virginians out there who disagree.\n",
      "damn i need to leave chucktown.\n",
      "4\n",
      "It means Charleston, South Carolina the best city in the world\n",
      "Almost like Atlanta, GA but alot better\n",
      "by Danny White December 27, 2003\n",
      "5\n",
      "A nickname for the city of Charleston, West Virginia.\n",
      "I live in chucktown.\n",
      "What does the name Madigan mean in Irish?\n",
      "The primary identifier of a family is its \"name.\" The patronymic of a family is the \"name\" derived from the father, which generally becomes the surname of any of the family's children.\n"
     ]
    }
   ],
   "source": [
    "import RAG_utils\n",
    "db = RAG_utils.access_lc_chroma_db('train_1000_200_all-MiniLM-L6-v2')\n",
    "question = 'What does the name Madigan mean in Irish?'\n",
    "\n",
    "system_message = \"\"\"You are a helpful assistant. Answer the user's question in one sentence based on the provided context. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. Do NOT start your response with \"According to the provided context.\" \"\"\"\n",
    "user_message_template = \"\"\"Context: {context} Question: {question}\"\"\"\n",
    "\n",
    "# Retrieve the answer\n",
    "docs = db.similarity_search(question, 11)\n",
    "for i, doc in enumerate(docs):\n",
    "    print('='*20, i, '='*20)\n",
    "    print(doc.page_content)\n",
    "\n",
    "\n",
    "context = RAG_utils.format_contexts([doc.page_content for doc in docs])\n",
    "user_message = user_message_template.format(context=context, question=question)\n",
    "\n",
    "answer = RAG_utils.gen_text_ollama(sys_msg=system_message, user_msg=user_message,options={'seed':0, 'temperature':0.01})\n",
    "print(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain\n",
      "Project Path: /Users/ryankish/Documents/Northwestern/Curriculum/Spring/MSAI 490 Practicum in Intelligent Systems/advanced_rag_team_twain\n",
      "{'elasticsearch': {'mikky': {'region': 'us-east-2', 'host': 'search-mikky-es-tkpsgqtkfdoy5kmpt4uprginoy.us-east-2.es.amazonaws.com', 'port': 443}, 'practicum': {'region': 'us-east-2', 'host': 'search-kcn5738-msai-practicum-5renmdtao2ribrht3jkdqbl75e.us-east-2.es.amazonaws.com', 'port': 443}}}\n"
     ]
    }
   ],
   "source": [
    "from utils.db.es import search_data, search_vector\n",
    "index_name = 'rag-dataset-12000-train-vector'\n",
    "k = 5\n",
    "question = 'What does the name Madigan mean in Irish?'\n",
    "es_contexts = [context['_source']['sentence'] for context in search_vector(question, index_name, k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['edit* my ancestors were from Clan Ross\\nFamily lore is that we were MacDonalds in Scotland, but chased out. Many family members moved to York and took the name Sturdy.',\n",
       " 'Challenge 10: Write a Story From a Movie You Like Hey, Everybody! Sorry it’s been so long. I’ve been working on this How To Train Your Dragon story a lot. […]\\nChallenge 4: Have two of your book characters from different book worlds meet. Write a short story about it. Writefury’s Characters Gilligan: From my first book: “Odd Team Out”. He […]\\nThought I’d add a little bit of Riley Trivia this time. Madigan means “small dog” in Irish. Magnus means “big” in latin. Chapter 6 Training Shyloh After her […]\\nCHAPTER 4 Not a Slave A few days later, all the Irish had been sold. Riley had been sold to a cranky old lady named Freyda. In Freyda’s house, Riley […]\\nCHAPTER 2 Captured Riley opened her eyes and stared upward. Two seagulls squawked overhead. The ground rocked underneath her. She sat up slowly, her head throbbing. Maddy barked happily, Riley […]',\n",
       " 'The History of Ancient Irish Civilization\\n[Pg v]\\nPREFACE..\\nBut the book has a further mission. There are many English and\\nmany Anglo-Irish people who think, merely from ignorance, that\\nIreland was a barbarous and half-savage country before the English\\ncame among the people and civilised them. This book, so far as it\\nfinds its way among the two classes above mentioned, will, I fancy,\\nopen their eyes. They will learn from it that the old Irish, so far from\\nbeing barbarous,\\n[Pg vi]\\nwere a bright, intellectual, and cultured people; that they had\\nprofessions, trades, and industries pervading the whole population,\\nwith clearly defined ranks and grades of society, all working under an\\nelaborate system of native laws; and that in the steadying and\\ncivilising arts and pursuits of everyday life they were as well\\nadvanced, as orderly, and as regular as any other European people\\nof the same period. They will find too that, as regards education,',\n",
       " 'Looking to the future, a resurgence in the popularity of traditional Scottish forenames in recent years is likely to combat Anglicisation, said Hough.\\n“Far more Gaelic and Celtic-derived personal names are being chosen by parents in Scotland, which can be a way of affirming national identity,” she says. “Gaelic-derived forenames that are in the top 100 names in Scotland at the moment include Aiden, Callum and Finlay. Cameron is originally a clan name, and Lewis, Evan and Isla are all place names.”\\nYou can view a map of Scotland’s most popular surnames at Tartan Footprint.Tagged\\nMy father is a Ross. How can I find out about our ancestors\\nMy father is a Simpson from Frazer clan. How can I find out about our ancestors?\\naccording to my grand mother some of my ancestors moved from Scotland to Finland in the early-mid 1700 but i do not know much else than that. it would be really helpful if someone could lead me to other sites and such where i can find out more of stuff like this.',\n",
       " 'In the Northern Isles Halcrow, Drever and Flett survive as the third most common surnames, while Shetland still boasts a diverse mix of Spences, Rendalls and Sinclairs. Carole Hough, professor of onomastics – the study of name origins – at Glasgow University, said the surnames of Orkney and Shetland differ from much of mainland Scotland due to naming traditions.\\n“Shetland and Orkney are unique in that they have a much higher proportion of surnames from local place names, which makes them quite distinctive. Place names tend to cluster around their origin, which is surprising given how mobile people are,” she added\\nThe English derived surname Smith is the most dominant across the whole of Great Britain with a considerable stronghold in the lowlands and east of Scotland. Modern-day immigration shows in areas such a Glasgow’s Pollokshield’s East, with Ahmed, Ali and Singh popular surnames. Jones, Davies and Williams dominate in Wales.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0,  4865, 14602,  ...,     1,     1,     1],\n",
      "        [    0,  4865, 14602,  ...,  4293,  1449,     2],\n",
      "        [    0,  4865, 14602,  ...,     1,     1,     1],\n",
      "        [    0,  4865, 14602,  ...,     5,     2,     1],\n",
      "        [    0,  4865, 14602,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "tensor([-9.4515,  3.5403, -9.4710, -9.3380, -6.0830])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Challenge 10: Write a Story From a Movie You Like Hey, Everybody! Sorry it’s been so long. I’ve been working on this How To Train Your Dragon story a lot. […]\\nChallenge 4: Have two of your book characters from different book worlds meet. Write a short story about it. Writefury’s Characters Gilligan: From my first book: “Odd Team Out”. He […]\\nThought I’d add a little bit of Riley Trivia this time. Madigan means “small dog” in Irish. Magnus means “big” in latin. Chapter 6 Training Shyloh After her […]\\nCHAPTER 4 Not a Slave A few days later, all the Irish had been sold. Riley had been sold to a cranky old lady named Freyda. In Freyda’s house, Riley […]\\nCHAPTER 2 Captured Riley opened her eyes and stared upward. Two seagulls squawked overhead. The ground rocked underneath her. She sat up slowly, her head throbbing. Maddy barked happily, Riley […]']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-large')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('BAAI/bge-reranker-large')\n",
    "model.eval()\n",
    "\n",
    "\n",
    "pairs = [[question, context] for context in es_contexts]\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "    print(inputs)\n",
    "    \n",
    "    scores = model(**inputs, return_dict=True).logits.view(-1, ).float()\n",
    "    print(scores)\n",
    "\n",
    "threshold = 0\n",
    "filtered_indices = torch.where(scores > threshold)[0]\n",
    "filtered_values = scores[filtered_indices]\n",
    "sorted_indices = torch.argsort(filtered_values, descending=True)\n",
    "indices = filtered_indices[sorted_indices]\n",
    "indices = indices.tolist()\n",
    "sorted_relevant_contexts = [es_contexts[i] for i in indices]\n",
    "sorted_relevant_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XLMRobertaTokenizerFast' object has no attribute 'passage_prefix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpassage_prefix\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'XLMRobertaTokenizerFast' object has no attribute 'passage_prefix'"
     ]
    }
   ],
   "source": [
    "tokenizer.passage_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> What does the name Madigan mean in Irish?</s></s> edit* my ancestors were from Clan Ross Family lore is that we were MacDonalds in Scotland, but chased out. Many family members moved to York and took the name Sturdy.</s>'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0,   4865,  14602,     70,   9351,    276,  63592,  29459,     23,\n",
       "        120552,     32,      2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(question, padding=False, truncation=False, return_tensors='pt', max_length=512)['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0,   4865,  14602,     70,   9351,    276,  63592,  29459,     23,\n",
       "        120552,     32,      2,      2,  27211,   1639,    759,      6,  60502,\n",
       "         22230,   3542,   1295, 165854,  53434,  59745,    459,    107,     83,\n",
       "           450,    642,   3542,   4727, 217258,      7,     23, 176637,      4,\n",
       "          1284,   1608,   5281,   1810,      5,  52455,  14449,  43032, 109133,\n",
       "            47,   5753,    136,  34739,     70,   9351,    159,    987,   1459,\n",
       "             5,      2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[     0,   4865,  14602,     70,   9351,    276,  63592,  29459,     23,\n",
      "         120552,     32,      2,      0,  27211,   1639,    759,      6,  60502,\n",
      "          22230,   3542,   1295, 165854,  53434,  59745,    459,    107,     83,\n",
      "            450,    642,   3542,   4727, 217258,      7,     23, 176637,      4,\n",
      "           1284,   1608,   5281,   1810,      5,  52455,  14449,  43032, 109133,\n",
      "             47,   5753,    136,  34739,     70,   9351,    159,    987,   1459,\n",
      "              5,      2]])\n",
      "tensor([[     0,   4865,  14602,     70,   9351,    276,  63592,  29459,     23,\n",
      "         120552,     32,      2,      0,  73630,    209,     12,    601,  18781,\n",
      "             10,  30575,  28090,     10,  10348,   2583,  18852,  28240,      4,\n",
      "          87769,  37873,     38,  90502,    442,     26,      7,   2809,    221,\n",
      "           4989,      5,     87,     26,    272,   2809,  20697,     98,    903,\n",
      "          11249,    717, 137879,  14804,  60884,  13765,     10,   5915,      5,\n",
      "           1449,  73630,  27959,  31901,   6626,    111,    935,  12877, 124850,\n",
      "           1295,  12921,  12877,   8999,      7,  23356,      5,    601,  18781,\n",
      "             10,  16610,  13765,   1672,    442,      5,    601,  18781,  11443,\n",
      "             53,     26,      7,  21656,   2263,  23962, 110226,  53437,     12,\n",
      "          28090,    759,   5117,  12877,     12,     52,    670,   4028,  11399,\n",
      "          13538,    792,   1529,   1449, 145733,     18,     87,     26,     71,\n",
      "          15190,     10,  10176,   4785,    111,   2975,   4293,   4699,   3459,\n",
      "            903,   1733,      5,    276,  63592,  26950,     52,      7,  69070,\n",
      "          10269,     63,     23, 120552,      5,  79949,  26950,     52,  32976,\n",
      "             63,     23,  45137,      5, 117615,    305,  44284,   7525,     53,\n",
      "          40289,  24372,    604,   1449,  25087,    683,  14755,    201,  11205,\n",
      "             10,  69125,     13,     62,  10846,  13312,  14432,      4,    756,\n",
      "             70, 120552,   1902,   2809,  54324,      5,   2975,   4293,   1902,\n",
      "           2809,  54324,     47,     10,   8374,     66,   1002,  10332, 108596,\n",
      "             24,   4806,  21612,  39207,      5,    360,  21612,  39207,     26,\n",
      "              7,  18276,      4,   2975,   4293,   1449,  25087,    683,  14755,\n",
      "            116,  14304,    987,    297,   2975,   4293, 142096,    604,  46223,\n",
      "            136,  19252,     71,   1257,  19364,      5,  32964,  15520, 146638,\n",
      "              7,     91,  13722,    434,  12225,    645,  31251,      5,    581,\n",
      "          61585,  13950,    297,   1379,     86,  10519,    604,      5,   4687,\n",
      "          11736,   1257, 191975,      4,    604,  10336,   5675,  21359,  23709,\n",
      "              5,   9266,   1459,   1909,  12225,    256,   7520,    538,      4,\n",
      "           2975,   4293,   1449,      2]])\n",
      "tensor([[     0,   4865,  14602,     70,   9351,    276,  63592,  29459,     23,\n",
      "         120552,     32,      2,      0,    581,  65786,    111,    893,  45964,\n",
      "         120552,  18543,  47691,    378,    683,    177,     81,    268,  23096,\n",
      "            919,  61019,      5,      5,   4966,     70,  12877,   1556,     10,\n",
      "          53333,  29752,      5,   8622,    621,   5941,  14941,    136,   5941,\n",
      "           2393,    365,      9,    568,  16507,   3395,   2750,   5351,      4,\n",
      "           2563,    538,   1295,  80523,   3956,      4,    450, 122963,    509,\n",
      "             10,  95974,  10821,    136,  23552,      9,  35892,   4588,  23295,\n",
      "           8108,     70,  14941,  21449,  54940,     70,   3395,    136,   9782,\n",
      "          52021,   2856,      5,   3293,  12877,      4,    221,   2060,    237,\n",
      "            442,   7413,      7,   6863,   3917,  54940,     70,   6626,  61112,\n",
      "          36917, 119056,      4,   1221,      4,     87,   1207,   2408,      4,\n",
      "           9803,   2363,  46223,      5,  10660,   1221,  30698,   1295,    442,\n",
      "            450,     70,  10332, 120552,      4,    221,   2060,   1295,   8035,\n",
      "          95974,  10821,      4,    378,    683,    177,    279,    268,   3542,\n",
      "             10, 124498,      4,  91768,    289,      4,    136,  29394,     71,\n",
      "           3395,     74,    450,   1836,   1902,  40124,      7,      4,  52350,\n",
      "              7,      4,    136,  95845,      7,    117,   2113,    214,     70,\n",
      "          28271,  43904,      4,    678, 123019,  61924,     71,  30648,      7,\n",
      "            136,  44000,      7,    111, 100510,      4,    756,  20697,   1379,\n",
      "            142, 121151,     13,   5426,    111,     24,   4935, 131703,     74,\n",
      "            136,    450,     23,     70,  67788,   1459,    214,    136,   9782,\n",
      "          72219,  81693,    136,   7398,  68879,      7,    111, 190704,   6897,\n",
      "           1836,   3542,    237,   5299, 175961,      4,    237,  12989,    538,\n",
      "              4,    136,    237,  20324,    237,   2499,   3789,  28811,   3395,\n",
      "            111,     70,   5701,  14922,      5,  10660,   1221,   7413,   5792,\n",
      "            450,      4,    237,  28601,      7,  53019,      4,      2]])\n",
      "tensor([[     0,   4865,  14602,     70,   9351,    276,  63592,  29459,     23,\n",
      "         120552,     32,      2,      0, 157268,     47,     70,  22690,      4,\n",
      "             10,   3332, 148791,     23,     70,   5700,   2481,    111,  89160,\n",
      "          50695,   4745,    100,   4342,   3716,     23,  17309,   5369,     83,\n",
      "          47041,     47,  30641,  32544,    238,  15032,      4,   2804,    572,\n",
      "          72089,      5,     52,  80908,   1286,  69704,   1771,    136, 202395,\n",
      "              9,    820,     14,   4126,   3357, 123055,    621,   8035,  19667,\n",
      "             19,    390,  27863,     23, 176637,      4,   3129,    831,    186,\n",
      "             10,   3917,    111,    261,  38949,    214,  15889, 182324,      4,\n",
      "             63,   2412,  17378,      5,     52,  17067,     13,   9120,      9,\n",
      "            820,     14,   4126,    100,   4342,   3716,    450,    621,     23,\n",
      "             70,   2663,    805, 123055,     23, 176637,     99,     70,   3095,\n",
      "          26698,     62,   6382,      4,  26265,    316,    136,  13316,   5259,\n",
      "              5, 100862,     83,   7311,    538,     10, 118820,   9351,      4,\n",
      "            136,  77330,      4, 107904,    136,  64704,    621,    756,   3687,\n",
      "         123055,    974,   2583,    831,  21455,     10,  22288,    111, 176637,\n",
      "             26,      7,   2684,   5700,    613,  11627,      7,     99,   6760,\n",
      "           1076, 159020,  35662,      5,  66448,  17704,   2646,  67373,     83,\n",
      "             10,  53434,      5,  11249,    831,     87,   7413,   1810,   1672,\n",
      "           2446,      6,  60502,  22230,   2646,  67373,     83,     10, 159929,\n",
      "           1295,   7868,   4383, 118820,      5,  11249,    831,     87,   7413,\n",
      "           1810,   1672,   2446,      6,  60502,  22230,     32,  59499,     47,\n",
      "            759,   9963,  42732,   3060,    111,    759,      6,  60502,  22230,\n",
      "         109133,   1295, 176637,     47,  29774,     23,     70,  39395,      9,\n",
      "          22000,  71792,   1284,     17,     54,    959,   3714,   5045,  37076,\n",
      "           3501,    450,      5,    442,   2806,    186,   6183,  98893,   2174,\n",
      "          22008,   5809,  37105,    163,     47,   3789,  15271,    136,   6044,\n",
      "           7440,     17,    831,   7413,   1810,   1286,    111,  41884,   1884,\n",
      "            903,      5,      2]])\n",
      "tensor([[     0,   4865,  14602,     70,   9351,    276,  63592,  29459,     23,\n",
      "         120552,     32,      2,      0,    360,     70, 182688,   2071,   1577,\n",
      "           4772,    238,  15555,      4, 152103,     42,    136,    563,  37356,\n",
      "         188545,    237,     70,  50960,   2684,  39210,    613,  11627,      7,\n",
      "              4,  12960,   4687,  74041,   7464,  72464,    933,     10,   9789,\n",
      "          17664,    111,   8019,  69098,      4,  63137,   5584,      7,    136,\n",
      "           6610, 186827,      7,      5,  61171,     13,    572,  72089,      4,\n",
      "          16030,    111,  22767,   1510,  41637,     46,     70,  35187,    111,\n",
      "           9351,  59665,      7,     46,     99, 181787,  12535,      4,   2804,\n",
      "             70,    613,  11627,      7,    111,   3347,     92,  10186,    136,\n",
      "           4687,  74041, 129927,   1295,   5045,    111,   5201,   1760, 176637,\n",
      "           4743,     47, 147453,  40250,      7,      5,     52,  72859,  74041,\n",
      "            136,   3347,     92,  10186,    621,  36998,     23,    450,   1836,\n",
      "            765,     10,   5045,  77546, 123875,    111,    613,  11627,      7,\n",
      "           1295,   4000,   3687, 123055,      4,   3129,  30482,   2856,  32233,\n",
      "         117781,   5844,      5,  41076, 123055,  17660,     47, 234737,  10932,\n",
      "           2363,  59665,      4,   3129,     83, 212615,  34475,   3642,  14288,\n",
      "           3395,    621,      4,     63,   2412,  49814,    581,  14941,  16406,\n",
      "           4126,    613,  11627,  37700,     83,     70,   2684,  73944,  36880,\n",
      "             70,  28271,    111,  32774, 130891,    678,     10, 150675,  37515,\n",
      "          16200,     23,     70,  27226,  15534,    136,     28,   4438,    111,\n",
      "         176637,      5,  18799,      9,   5636,      6, 199417,  45831,     23,\n",
      "          58555,   6044,     10, 181787,     26,      7, 163498,    685, 221292,\n",
      "             26,      7,  24453,      4,    678,  36592,      4,   2132,    136,\n",
      "          25961,   5700,    613,  11627,      7,      5,  29304,      4, 151466,\n",
      "            136,  40478,  35462,     67,     23,  82588,      5,      2]])\n",
      "[tensor([-9.4256]), tensor([3.9644]), tensor([-9.4675]), tensor([-9.3693]), tensor([-7.3216])]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-large')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('BAAI/bge-reranker-large')\n",
    "model.eval()\n",
    "\n",
    "# Tokenize the question once\n",
    "question_tokens = tokenizer(question, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "\n",
    "# Tokenize the contexts\n",
    "context_tokens = [tokenizer(context, padding=True, truncation=True, return_tensors='pt', max_length=512) for context in es_contexts]\n",
    "\n",
    "# Concatenate the question tokens with each context token\n",
    "pairs_tokens = [torch.cat((question_tokens['input_ids'], context_token['input_ids']), dim=1) for context_token in context_tokens]\n",
    "\n",
    "# Create attention masks for the pairs\n",
    "pairs_attention_masks = [torch.cat((question_tokens['attention_mask'], context_token['attention_mask']), dim=1) for context_token in context_tokens]\n",
    "\n",
    "with torch.no_grad():\n",
    "    scores = []\n",
    "    for pair_input_ids, pair_attention_mask in zip(pairs_tokens, pairs_attention_masks):\n",
    "        print(pair_input_ids)\n",
    "        \n",
    "        inputs = {\n",
    "            'input_ids': pair_input_ids,\n",
    "            'attention_mask': pair_attention_mask\n",
    "        }\n",
    "        score = model(**inputs, return_dict=True).logits.view(-1, ).float()\n",
    "        scores.append(score)\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     0,  27211,   1639,    759,      6,  60502,  22230,   3542,   1295,\n",
       "         165854,  53434,  59745,    459,    107,     83,    450,    642,   3542,\n",
       "           4727, 217258,      7,     23, 176637,      4,   1284,   1608,   5281,\n",
       "           1810,      5,  52455,  14449,  43032, 109133,     47,   5753,    136,\n",
       "          34739,     70,   9351,    159,    987,   1459,      5,      2]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_tokens[0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'edit* my ancestors were from Clan Ross\\nFamily lore is that we were MacDonalds in Scotland, but chased out. Many family members moved to York and took the name Sturdy.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_contexts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0,   4865,  14602,     70,   9351,    276,  63592,  29459,     23,\n",
       "        120552,     32,      2,      2,  27211,   1639,    759,      6,  60502,\n",
       "         22230,   3542,   1295, 165854,  53434,  59745,    459,    107,     83,\n",
       "           450,    642,   3542,   4727, 217258,      7,     23, 176637,      4,\n",
       "          1284,   1608,   5281,   1810,      5,  52455,  14449,  43032, 109133,\n",
       "            47,   5753,    136,  34739,     70,   9351,    159,    987,   1459,\n",
       "             5,      2])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'][0]# == pair_input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-9.4460,  4.2120, -9.3817, -9.0143, -6.9692])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What does the name Madigan mean in Irish?</s> edit* my ancestors were from Clan Ross Family lore is that we were MacDonalds in Scotland, but chased out. Many family members moved to York and took the name Sturdy.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-large')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('BAAI/bge-reranker-large')\n",
    "model.eval()\n",
    "\n",
    "# Tokenize the question once\n",
    "question_tokens = tokenizer(question, add_special_tokens=False)\n",
    "\n",
    "# Prepare the pairs\n",
    "pairs = [[question, context] for context in es_contexts]\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# Manually concatenate tokens with the [SEP] token in between\n",
    "for pair in pairs:\n",
    "    context_tokens = tokenizer(pair[1], add_special_tokens=False)\n",
    "    \n",
    "    # Concatenate question, [SEP] token, and context tokens\n",
    "    input_id = question_tokens['input_ids'] + [tokenizer.sep_token_id] + context_tokens['input_ids']\n",
    "    attention_mask = [1] * len(input_id)\n",
    "    \n",
    "    input_ids.append(input_id)\n",
    "    attention_masks.append(attention_mask)\n",
    "\n",
    "# Pad sequences to the same length\n",
    "max_length = min(512, max(len(ids) for ids in input_ids))\n",
    "input_ids = [ids + [tokenizer.pad_token_id] * (max_length - len(ids)) for ids in input_ids]\n",
    "attention_masks = [mask + [0] * (max_length - len(mask)) for mask in attention_masks]\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "input_ids = torch.tensor(input_ids)\n",
    "attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = {'input_ids': input_ids, 'attention_mask': attention_masks}\n",
    "    scores = model(**inputs, return_dict=True).logits.view(-1).float()\n",
    "    print(scores)\n",
    "input_ids[0]\n",
    "tokenizer.decode(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-9.4276,  4.1190, -9.4661, -9.3947, -6.7785])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-large')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('BAAI/bge-reranker-large')\n",
    "model.eval()\n",
    "\n",
    "# Tokenize the question once, adding start and end tokens\n",
    "question_tokens = tokenizer(question, add_special_tokens=False)\n",
    "question_tokens['input_ids'] = [tokenizer.cls_token_id] + question_tokens['input_ids'] + [tokenizer.sep_token_id]\n",
    "\n",
    "# Prepare the pairs\n",
    "pairs = [[question, context] for context in es_contexts]\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# Manually concatenate tokens with the [SEP] token in between\n",
    "for pair in pairs:\n",
    "    context_tokens = tokenizer(pair[1], add_special_tokens=False)\n",
    "    context_tokens['input_ids'] = context_tokens['input_ids'] + [tokenizer.sep_token_id] # Add end token to context\n",
    "    \n",
    "    # Concatenate question, [SEP] token, and context tokens\n",
    "    input_id = question_tokens['input_ids'] + context_tokens['input_ids']\n",
    "    attention_mask = [1] * len(input_id)\n",
    "    \n",
    "    input_ids.append(input_id)\n",
    "    attention_masks.append(attention_mask)\n",
    "\n",
    "# Pad sequences to the same length\n",
    "max_length = min(512, max(len(ids) for ids in input_ids))\n",
    "input_ids = [ids + [tokenizer.pad_token_id] * (max_length - len(ids)) for ids in input_ids]\n",
    "attention_masks = [mask + [0] * (max_length - len(mask)) for mask in attention_masks]\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "input_ids = torch.tensor(input_ids)\n",
    "attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = {'input_ids': input_ids, 'attention_mask': attention_masks}\n",
    "    scores = model(**inputs, return_dict=True).logits.view(-1).float()\n",
    "    print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> What does the name Madigan mean in Irish?</s> edit* my ancestors were from Clan Ross Family lore is that we were MacDonalds in Scotland, but chased out. Many family members moved to York and took the name Sturdy.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0,   4865,  14602,     70,   9351,    276,  63592,  29459,     23,\n",
       "        120552,     32,      2,  27211,   1639,    759,      6,  60502,  22230,\n",
       "          3542,   1295, 165854,  53434,  59745,    459,    107,     83,    450,\n",
       "           642,   3542,   4727, 217258,      7,     23, 176637,      4,   1284,\n",
       "          1608,   5281,   1810,      5,  52455,  14449,  43032, 109133,     47,\n",
       "          5753,    136,  34739,     70,   9351,    159,    987,   1459,      5,\n",
       "             2,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c4c49fa7b0464a8bea3db3b0b286ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1006ee8ae6f84a62948de0aeb55cc1b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1b9a169bac47109415c12e7866c194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b045a8d3994c05bed5b24d070fe6cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2351e-04, 9.9988e-01],\n",
      "        [9.9972e-01, 2.7708e-04]])\n",
      "tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Example texts\n",
    "texts = [\"I love this!\", \"I hate this...\"]\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "# Forward pass, get logits\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Apply softmax to get probabilities\n",
    "probabilities = torch.softmax(logits, dim=-1)\n",
    "predictions = torch.argmax(probabilities, dim=-1)\n",
    "\n",
    "print(probabilities)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1045, 2293, 2023,  999,  102,    0,    0],\n",
       "        [ 101, 1045, 5223, 2023, 1012, 1012, 1012,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] i hate this... [SEP]'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs['input_ids'][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
